{
  
    
        "post0": {
            "title": "Functions Description",
            "content": "1. Axulliary Functions and Classes . 1.1 Plotting Functions . Below is the main plotting function, which is creates or uses existing axes to plot multiple functions. Optionally we apply scaling and limits x and y values. . From the functions point of view there is nothing really interesting going on. I provided key comments below in most places. We create two auxilliary functions - set_axes and set_global_graph_params. . `set_axes` sets labels, limits and scale for the x and y axis. | `set_global_graph_params` sets figure size and adjusts background color to dark_background | . def set_axes(axes: plt.Axes, xlabel: str, ylabel: str, xlim: Union[int, float], ylim: Union[int, float], xscale: str, yscale: str, legend: List[str]) -&gt; plt.Axes: &quot;&quot;&quot; Customizes the provided axes according to the provided parameters &quot;&quot;&quot; # set labels axes.set_xlabel(xlabel) axes.set_ylabel(ylabel) # must be used before setting `xlim` and `ylim` to avoid distorting the graph axes.set_xscale(xscale) axes.set_yscale(yscale) # set limits axes.set_xlim(xlim) axes.set_ylim(ylim) # add legend if legend is not None: axes.legend(legend) # add square grid axes.grid() return axes def set_global_graph_params(figsize: Tuple[float, float] = (3.5, 2.5), darkmode: bool = False): &quot;&quot;&quot; Use plt parameters to set the figure size and background style. For more details please refer to: https://matplotlib.org/3.5.0/tutorials/introductory/customizing.html#customizing-with-dynamic-rc-settings &quot;&quot;&quot; # set size of the figure - width, height plt.rcParams[&#39;figure.figsize&#39;] = figsize display.set_matplotlib_formats(&#39;png&#39;) # use if dark background is enables if darkmode: plt.style.use(&quot;dark_background&quot;) . . plot is the main plotting function that takes list or array of X values, corresponding list of Y values (functions on X) and plots those functions on a graph using different predetermined styles. . The code snippet below checks if X and Y have one axis (either a list or array with one dimension). If this condition is true, than it creates lists for both X and Y in order to be able to compare the their respective length. This is usefull when Y is an array of several functions over X $ (f(x), space f^{&#39;}(x)) $. Then X will be repeated twice for both functions. . if has_one_axis(X): X = [X] if Y is None: X, Y = [[]]*len(X), X elif has_one_axis(Y): Y = [Y] . def plot(X: Union[list, torch.Tensor], Y:Union[list, torch.Tensor] = None, xlabel: str = None, ylabel: str = None, legend: List[str] = None, xlim: Union[int, float] = None, ylim: Union[int, float] = None, xscale: str = &#39;linear&#39;, yscale: str = &#39;linear&#39;, fmts: Tuple[str] = (&#39;-&#39;, &#39;m--&#39;, &#39;g-.&#39;, &#39;r:&#39;), figsize: Tuple[float, float] = (3.5, 2.5), axes: plt.Axes = None, darkmode: bool = False): &quot;&quot;&quot; Main plotting function that takes `X` as an array and Y as a list of tensors (functions on `X`). Optionally applies scaling and limits on x and y axis &quot;&quot;&quot; set_global_graph_params(figsize, darkmode) axes = axes if axes else plt.gca() def has_one_axis(X): &quot;&quot;&quot; Check if X is a 1-d list of 1-d tensor / array &quot;&quot;&quot; return (hasattr(X, &quot;ndim&quot;) and X.ndim == 1) or (isinstance(X, list) and (not hasattr(X[0], &quot;__len__&quot;))) if has_one_axis(X): X = [X] # for the step below when we repeat X the len(y) times. Without it list will just increase in size if Y is None: X, Y = [[]]*len(X), X # convenience to run the loop below (zip). Basically defaults to `axes.plot(y, fmt)` elif has_one_axis(Y): Y = [Y] # adjust `X` for the length of `Y` by repeating `X` len(`Y`) times if len(X) != len(Y): X = X * len(Y) if axes is None: axes = plt.gca() plt.cla() for x, y, fmt in zip(X, Y, fmts): if len(x): axes.plot(x, y, fmt) else: axes.plot(y, fmt) set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend) . . Examples . X = list(range(1, 100, 1)) plot(X=X, xlabel=&quot;X&quot;, ylabel=&quot;Y&quot;, legend=[&quot;Simple case 1&quot;]); . X = np.arange(0, 100, 0.1) plot(X=X, Y=[x**2 for x in X], xlabel=&quot;X&quot;, ylabel=&quot;Y&quot;, legend=[&quot;Simple case 2&quot;]); . X = np.arange(0, 100, 0.1) Y1 = X**2 - 10*X Y2 = 50*X Y3 = Y1 + Y2 plot(X=X, Y=[Y1, Y2, Y3], xlabel=&quot;X&quot;, ylabel=&quot;Y&quot;, legend=[&quot;X**2&quot;, &quot;50*X&quot;, &quot;X**2 + 50*X&quot;], figsize=[5, 4]); . def show_images(imgs: Union[torch.Tensor, np.ndarray], num_rows: int, num_cols: int, titles: List[str] = None, scale: float = 1.5): &quot;&quot;&quot;Plot a list of images.&quot;&quot;&quot; # since width comes first when we set it in `plt.rcParams[&#39;figure.figsize&#39;]` figsize = (num_cols * scale, num_rows * scale) # returs figure and axes. axes is numpy.ndarray of shape (num_rows, num_cols) _, axes = plt.subplots(num_rows, num_cols,figsize=figsize) # we flatten axes to make it easier to index them axes = axes.flatten() for i, (ax, img) in enumerate(zip(axes, imgs)): if torch.is_tensor(img): # this is a Tensor image ax.imshow(img.numpy()) else: # PIL image ax.imshow(img) # turn off axis for plotting images ax.axes.get_xaxis().set_visible(False) ax.axes.get_yaxis().set_visible(False) if titles: ax.set_title(titles[i]) return axes . X, y = next(iter(data.DataLoader(mnist_train, batch_size=18))) show_images(X.reshape(18, 28, 28), 2, 9, titles=get_fashion_mnist_labels(y)); . We use the Animator class to plot data in animation . class Animator: &quot;&quot;&quot;Plots data in animation&quot;&quot;&quot; def __init__(self, xlabel: str = None, ylabel: str = None, legend: List[str] = [], xlim:int = None, ylim:int = None, xscale: str = &#39;linear&#39;, yscale: str = &#39;linear&#39;, fmts: Tuple[str] = (&#39;-&#39;, &#39;m--&#39;, &#39;g-.&#39;, &#39;r:&#39;), nrows: int = 1, ncols: int = 1, figsize: Tuple[float] = (3.5, 2.5)): # Incrementally plot multiple lines self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize) # make self.axes always a list to run the lambda below if nrows * ncols == 1: self.axes = [self.axes] # use lambda function to capture arguments self.config_axes = lambda: set_axes(axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend) self.X, self.Y, self.fmts = None, None, fmts def add(self, x, y): # Add multiple data points into the figure if not hasattr(y, &quot;__len__&quot;): y = [y] n = len(y) # if x is not a list and y is a list with more than 1 element, repeat `x` for each `y` if not hasattr(x, &quot;__len__&quot;): x = [x] * n # Initialize X and Y during the first run. Length of x sets the number of lines to be plotted if not self.X: self.X = [[] for _ in x] if not self.Y: self.Y = [[] for _ in y] # for each sublist in x and y append them to X and Y # each sublist in X and Y refers to seperate line and is plotted it its own color for i, (a, b) in enumerate(zip(x, y)): if a is not None and b is not None: self.X[i].append(a) # ith element of `x` appends to the i-th sublist of X self.Y[i].append(b) self.axes[0].cla() # Plot all of the sublists of X and Y for x, y, fmt in zip(self.X, self.Y, self.fmts): self.axes[0].plot(x, y, fmt) self.config_axes() display.display(self.fig) display.clear_output(wait=True) . animator = Animator(xlabel=&quot;x&quot;, ylabel=&quot;y&quot;,legend=[&quot;x1, x2&quot;]) for i in range(10): xs = np.array([i, i, i, i]) ys = np.array([10, 20, 30, 40]) animator.add(xs, ys) #break . 1.2 Auxillary classes . class Timer: &quot;&quot;&quot;Record multiple running times&quot;&quot;&quot; def __init__(self): self.times = [] self.start() def start(self): &quot;&quot;&quot;Start the timer.&quot;&quot;&quot; self.tik = time.time() def stop(self): &quot;&quot;&quot;Stop the timer and record the time in a list.&quot;&quot;&quot; self.times.append(time.time() - self.tik) return self.times[-1] def avg(self): &quot;&quot;&quot;Return the average time.&quot;&quot;&quot; return sum(self.times) / len(self.times) def cumsum(self): &quot;&quot;&quot;Return the accumulated time.&quot;&quot;&quot; return np.array(self.times).cumsum().tolist() . . class Accumulator: &quot;&quot;&quot;Accumulates sums over `n` variables&quot;&quot;&quot; def __init__(self, n: int): &quot;&quot;&quot;Inititalize with zeros an array of size `n`&quot;&quot;&quot; self.data = [0.0] * n def add(self, *args): self.data = [a + float(b) for a,b in zip(self.data, args)] def reset(self): &quot;&quot;&quot;Set all data entries to zero&quot;&quot;&quot; self.data = [0.0] * len(self.data) def __getitem__(self, idx: int): &quot;&quot;&quot;Getter - simply return an element by index from self.data&quot;&quot;&quot; return self.data[idx] . Note that 4 is ignored as Accumulator accepts only 3 items . d = Accumulator(3) print(d.data) d.add(1,2,3,4) print(d.data) . [0.0, 0.0, 0.0] [1.0, 2.0, 3.0] . Examples . As a simple example we create two torch tensors of length 10 000 and add them up in in a loop. We can use Timer to measure how long it takes for the code to run. At the same time please note that using jupyter magic command %%timeit is more reliable due to the following reasons: . `Timer` relies only on a single calculation and thus is sensitive to other processes that may be running in the OS at the current moment. %%timeit at the same time averages its calculation thus reducing the influence of parallel processes / tasks | `%%timeit disables the garbage collector to minimize influence of a collection run at during code timing. | . n = 10000 a = torch.ones(n) b = torch.ones(n) . timer = Timer() timer.start() c = [] for i in range(len(b)): c.append(a[i] + b[i]) print(f&#39;{timer.stop():.5f} sec&#39;) . 0.15946 sec . %%timeit c = [] for i in range(len(b)): c.append(a[i] + b[i]) . 39.1 ms ± 641 µs per loop (mean ± std. dev. of 7 runs, 10 loops each) . 1.3 Auxilliary functions . synthetic_data is used to create simple linear layer . def synthetic_data(w: torch.Tensor, b: Union[torch.Tensor, float], num_examples: int) -&gt; torch.Tensor: &quot;&quot;&quot;Generate y = Xw + b + noise, where y.shape is (num_examples, 1)&quot;&quot;&quot; X = torch.normal(mean=0, std=1, size=(num_examples,len(w))) # create X from normal distrubtion y = X@w + b # Calculate y by using matrix multiplication `@` y += torch.normal(mean=0, std=0.01, size=y.shape) # if `w` is a 1-dimensional tensor, than y will be also a 1-dimensional tensor with shape [num_examples] # we reshape `y` to be of shape [num_examples,1] return X, y.reshape(-1,1) . def linreg(X: torch.Tensor, w: torch.Tensor, b: Union[torch.Tensor, float]) -&gt; torch.Tensor: &quot;&quot;&quot;Returns Linear layer defined by y = X @ w + b&quot;&quot;&quot; assert X.shape[-1] == w.shape[0], f&#39;Got incorrect shapes for matrix multiplication. X.shape: {X.shape} and w.shape: {w.shape}&#39; return X@w + b . def squared_loss(y_hat: torch.Tensor, y: torch.Tensor) -&gt; torch.Tensor: return (y_hat-y.reshape(y_hat))**2/2 . Update the parameters $( textbf w,b) leftarrow ( textbf w,b) - nu times g$, where . $ nu$ is the learning rate | $g$ is the gradient: $ g leftarrow delta_{w, b} frac{1}{|B|} sum_{i in B} l( textbf x^{(i)}, y^{(i)}, textbf w, b)$ | . def sgd(params: List[torch.Tensor], lr: float, batch_size: int): &quot;&quot;&quot;Minibatch stochastic gradient descent.&quot;&quot;&quot; with torch.no_grad(): # disable the torch gradient calculation for the context for param in params: param -= lr * param.grad / batch_size_size param.grad.zero_() . def accuracy(y_hat: torch.Tensor, y: torch.Tensor): &quot;&quot;&quot;Compute the number of correct predictions&quot;&quot;&quot; # check if y_hat has more than one dimesnion and that dimension has values # e.g. if y is [[0.1,0.5,0.4], [0.5,0.5,0.7]] -&gt; [1,2] if len(y_hat.shape) &gt; 1 and y_hat.shape[1] &gt; 1: y_hat = y_hat.argmax(axis=1) # calculate tensor with 0 (false) and 1 (true) cmp = y_hat.type(y.dtype) == y return float(cmp.type(y.dtype).sum()) . def evaluate_accuracy(net: nn.Module, data_iter): &quot;&quot;&quot;Compute the accuracy for a model on a dataset.&quot;&quot;&quot; if isinstance(net, torch.nn.Module): net.eval() # Set the model to evaluation mode metric = Accumulator(2) # Store No. of correct predictions, no. of predictions with torch.no_grad(): for X, y in data_iter: metric.add(accuracy(net(X), y), y.numel()) return metric[0] / metric[1] . Examples . w = torch.tensor([2, -3.4]) b = 4.2 features, labels = synthetic_data(w, b, 1000) features.shape, labels.shape . (torch.Size([1000, 2]), torch.Size([1000, 1])) . X = torch.normal(0, 1, size=(5,2)) w = torch.tensor([2, -3.4]) b = 4.2 linreg(X, w, b) . tensor([ 7.7977, -0.1157, 5.6153, 1.9826, 2.2314]) . test = torch.tensor( [[0.1,0.5,0.4], [0.5,0.5,0.7]]) true = torch.tensor([1,2]) accuracy(test, true) . 2.0 . 1.4 Data Manipulation . Function load_array returns DataLoader that generates batches of data of size _batchsize. To get new batch of data we use . data_iterator = load_array(args) next(iter(data_iterator) . def load_array(data_arrays: List[torch.Tensor], batch_size: int, is_train: bool = True) -&gt; DataLoader: &quot;&quot;&quot;Construct a PyTorch data iterator.&quot;&quot;&quot; dataset = data.TensorDataset(*data_arrays) # analagous to data.TensorDataset(X, Y, ...) return data.DataLoader(dataset, batch_size, suffle=is_train) . 1.5 Datasets Functions . def get_fashion_mnist_labels(labels: List[float]): &quot;&quot;&quot;Return text labels for the Fashion-MNIST dataset.&quot;&quot;&quot; text_labels = [&#39;t-shirt&#39;, &#39;trouser&#39;, &#39;pullover&#39;, &#39;dress&#39;, &#39;coat&#39;, &#39;sandal&#39;, &#39;shirt&#39;, &#39;sneaker&#39;, &#39;bag&#39;, &#39;ankle boot&#39;] return [text_labels[int(i)] for i in labels] . def get_dataloader_workers(): &quot;&quot;&quot;Use 4 processes to read data&quot;&quot;&quot; return 4 . def load_data_fashion_mnist(batch_size: int, resize: Union[Tuple[int], int] = None) -&gt; Tuple[DataLoader, DataLoader]: &quot;&quot;&quot;Download the Fashion-MNIST dataset and load it into memory&quot;&quot;&quot; trans = [transforms.ToTensor()] if resize: trans.insert(0, transforms.Resize(resize)) # compose together transformations trans = transforms.Compose(trans) # create training and test sets from FashionMNIST by downloading the data into &quot;/..data&quot; mnist_train = torchvision.datasets.FashionMNIST(&quot;../data&quot;, train=True, download=True, transform=trans) mnist_test = torchvision.datasets.FashionMNIST(&quot;../data&quot;, train=False, download=True, transform=trans) return (data.DataLoader(mnist_train, batch_size, shuffle=True, num_workers=get_dataloader_workers()), data.DataLoader(mnist_test, batch_size, shuffle=False, num_workers=get_dataloader_workers())) . Examples . train_iter, test_iter = load_data_fashion_mnist(32, resize=64) for X, y in train_iter: print(X.shape, X.dtype, y.shape, y.dtype) break . torch.Size([32, 1, 64, 64]) torch.float32 torch.Size([32]) torch.int64 . 2.0 Training nets . Trains net for one epoch . def train_epoch_ch3(net: Union[nn.Module, Callable[[torch.Tensor],torch.Tensor]], train_iter: DataLoader, loss: Callable[[torch.Tensor], None], updater: Callable[[torch.Tensor], None]) -&gt; Tuple[float, float]: &quot;&quot;&quot;Training loop for one epoch from chapter 3 of d2l&quot;&quot;&quot; # set the model to training mode if isinstance(net, torch.nn.Module): net.train() # Sum of training loss, sum of training accuracy, no. of examples metric = Accumulator(3) for X, y in train_iter: # Compute gradients of parameters y_hat = net(X) l = loss(y_hat, y) if isinstance(updater, torch.optim.Optimizer): # Using PyTorch in-built optimizer &amp; loss criterion updater.zero_grad() l.mean().backward() updater.step() else: # Using custom built optimizer &amp; loss criterion l.sum().backward() updater(X.shape[0]) # batch_size metric.add(float(l.sum(), accuracy(y_hat, y), y.numel())) # Return training loss and training accuracy return metric[0] / metric[2], metric[1] / metric[2] . torch . &lt;module &#39;torch&#39; from &#39;/usr/local/lib/python3.8/dist-packages/torch/__init__.py&#39;&gt; .",
            "url": "https://iamalos.github.io/coding-blog/first-post/",
            "relUrl": "/first-post/",
            "date": " • Jun 14, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://iamalos.github.io/coding-blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://iamalos.github.io/coding-blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://iamalos.github.io/coding-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://iamalos.github.io/coding-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}